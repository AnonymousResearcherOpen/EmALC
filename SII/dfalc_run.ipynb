{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SII Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "# Generate data in different types\n",
    "data_training_dir = \"/data/data_wuxuan/SII/data/training/\"\n",
    "data_testing_dir = \"/data/data_wuxuan/SII/data/testing/\"\n",
    "zero_distance_threshold = 6\n",
    "number_of_features = 65\n",
    "name = \"indoor\"\n",
    "types = {}\n",
    "with open(\"data/classes.csv\", \"r\") as f:\n",
    "    cnt = 0\n",
    "    for line in f.readlines():\n",
    "        types[line.strip()] = cnt\n",
    "        cnt += 1\n",
    "        \n",
    "if name == \"vehicle\":\n",
    "    # uncomment this line for training the vehicle object types\n",
    "    selected_types_name = np.array(['aeroplane','artifact_wing','body','engine','stern','wheel','bicycle','chain_wheel','handlebar','headlight','saddle','bus','bodywork','door','license_plate','mirror','window','car','motorbike','train','coach','locomotive','boat'])\n",
    "\n",
    "if name == \"indoor\":\n",
    "    # uncomment this line for training the indoor object types\n",
    "    selected_types_name = np.array(['bottle','body','cap','pottedplant','plant','pot','tvmonitor','screen']) #'chair','sofa','diningtable'\n",
    "\n",
    "if name == \"animal\":\n",
    "    # uncomment this line for training the animal object types\n",
    "    selected_types_name = np.array(['person','arm','ear','ebrow','foot','hair','hand','mouth','nose','eye','head','leg','neck','torso','cat','tail','bird','animal_wing','beak','sheep','horn','muzzle','cow','dog','horse','hoof'])\n",
    "\n",
    "\n",
    "\n",
    "selected_types = [types[n] for n in selected_types_name]\n",
    "\n",
    "\n",
    "def containment_ratios_between_two_bbxes(bb1, bb2):\n",
    "    bb1_area = (bb1[-2] - bb1[-4]) * (bb1[-1] - bb1[-3])\n",
    "    bb2_area = (bb2[-2] - bb2[-4]) * (bb2[-1] - bb2[-3])\n",
    "    w_intersec = max(0,min([bb1[-2], bb2[-2]]) - max([bb1[-4], bb2[-4]]))\n",
    "    h_intersec = max(0,min([bb1[-1], bb2[-1]]) - max([bb1[-3], bb2[-3]]))\n",
    "    bb_area_intersection = w_intersec * h_intersec\n",
    "    return [float(bb_area_intersection)/bb1_area, float(bb_area_intersection)/bb2_area]\n",
    "\n",
    "def get_data(train_or_test_swritch,max_rows=10000000):\n",
    "    assert train_or_test_swritch == \"train\" or train_or_test_swritch == \"test\"\n",
    "\n",
    "    # Fetching the data from the file system\n",
    "\n",
    "    if train_or_test_swritch == \"train\":\n",
    "        data_dir = data_training_dir\n",
    "    if train_or_test_swritch == \"test\":\n",
    "        data_dir = data_testing_dir\n",
    "    data = np.genfromtxt(data_dir+\"features.csv\",delimiter=\",\",max_rows=max_rows)\n",
    "    types_of_data = np.genfromtxt(data_dir + \"types.csv\", dtype=\"i\", max_rows=max_rows)\n",
    "    idx_whole_for_data = np.genfromtxt(data_dir+ \"partOf.csv\",dtype=\"i\",max_rows=max_rows)\n",
    "    idx_of_cleaned_data = np.where(np.logical_and(\n",
    "        np.all(data[:, -2:] - data[:, -4:-2] >= zero_distance_threshold, axis=1),\n",
    "        np.in1d(types_of_data,selected_types)))[0]\n",
    "    print(\"deleting\", len(data) - len(idx_of_cleaned_data), \"small bb out of\", data.shape[0], \"bb\")\n",
    "    data = data[idx_of_cleaned_data]\n",
    "    data[:, -4:] /= 500\n",
    "\n",
    "    # Cleaning data by removing small bounding boxes and recomputing indexes of partof data\n",
    "\n",
    "    types_of_data = types_of_data[idx_of_cleaned_data]\n",
    "    idx_whole_for_data = idx_whole_for_data[idx_of_cleaned_data]\n",
    "    for i in range(len(idx_whole_for_data)):\n",
    "        if idx_whole_for_data[i] != -1 and idx_whole_for_data[i] in idx_of_cleaned_data:\n",
    "            idx_whole_for_data[i] = np.where(idx_whole_for_data[i] == idx_of_cleaned_data)[0]\n",
    "        else:\n",
    "            idx_whole_for_data[i] = -1\n",
    "\n",
    "    # Grouping bbs that belong to the same picture\n",
    "\n",
    "    pics = {} #记录了每张图片对应的bbox，即data的id\n",
    "    for i in range(len(data)):\n",
    "        if data[i][0] in pics:\n",
    "            pics[data[i][0]].append(i)\n",
    "        else:\n",
    "            pics[data[i][0]] = [i]\n",
    "\n",
    "    pairs_of_data = np.array(\n",
    "        [np.concatenate((data[i][1:], data[j][1:], containment_ratios_between_two_bbxes(data[i], data[j]))) for p in\n",
    "         pics for i in pics[p] for j in pics[p]])\n",
    "\n",
    "    pairs_of_bb_idxs = np.array([(i,j) for p in pics for i in pics[p] for j in pics[p]]) #枚举同一张图片里不同objects(bbox) pair\n",
    "\n",
    "    partOf_of_pair_of_data = np.array([idx_whole_for_data[i] == j for p in pics for i in pics[p] for j in pics[p]])\n",
    "\n",
    "    return data, pairs_of_data, types_of_data, partOf_of_pair_of_data, pairs_of_bb_idxs, pics\n",
    "\n",
    "\n",
    "data, pairs_of_data, types_of_data, partOf_of_pairs_of_data, pairs_of_bb_idxs, pics = get_data(\"test\",max_rows=1000000000)\n",
    "print(\"individual size: \", data.shape[0], \"concept size: \", data.shape[1]-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data for DF-ALC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import require\n",
    "from Dataset import OntologyDataset\n",
    "from model import DFALC\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "conceptSize = len(types)\n",
    "roleSize = 1\n",
    "individualSize = data.shape[0]\n",
    "cEmb_candid = torch.Tensor(data[:,1:-4])\n",
    "rEmb_candid = torch.zeros(1, individualSize, individualSize)\n",
    "partOf_of_pairs_idx = np.where(partOf_of_pairs_of_data)[0]\n",
    "for idx,(i,j) in enumerate(pairs_of_bb_idxs):\n",
    "    i_partof_j_p, j_partof_i_p = pairs_of_data[idx][-2], pairs_of_data[idx][-1]\n",
    "    if i_partof_j_p == 1: j_partof_i_p = 0\n",
    "    if j_partof_i_p == 1: i_partof_j_p = 0\n",
    "    rEmb_candid[0,i,j] = i_partof_j_p\n",
    "    rEmb_candid[0,j,i] = j_partof_i_p\n",
    "\n",
    "info_path = \"data\"\n",
    "file_name = \"PascalPartOntology_\"+name+\".owl\"\n",
    "with open(os.path.join(info_path,file_name+\"_roles.txt\"),\"w\") as f:\n",
    "    f.write(\"http://www.w3.org/2002/07/partOf\")\n",
    "with open(os.path.join(info_path,file_name+\"_individuals.txt\"),\"w\") as f:\n",
    "    individuals = []\n",
    "    for p in pics:\n",
    "        for i in pics[p]:\n",
    "            f.write(str(i) + \"\\n\")\n",
    "\n",
    "params = {\n",
    "        \"conceptPath\": os.path.join(info_path,file_name+\"_concepts.txt\"),\n",
    "        \"rolePath\": os.path.join(info_path,file_name+\"_roles.txt\"),\n",
    "        \"individualPath\": os.path.join(info_path,file_name+\"_individuals.txt\"),\n",
    "        \"normalizationPath\": os.path.join(info_path,file_name+\"_normalization.txt\"),\n",
    "        \"batchSize\": 3,\n",
    "        \"epochSize\":10,\n",
    "        \"earlystopping\":10,\n",
    "        \"dist\": \"minkowski\",\n",
    "        \"norm\":1,\n",
    "        \"norm_rate\":0.5,\n",
    "        \"norm_rate2\":0\n",
    "    }\n",
    "to_train = False\n",
    "\n",
    "save_path = \"data\"\n",
    "if to_train: save_path = os.path.join(save_path,\"training\")\n",
    "else: save_path = os.path.join(save_path,\"testing\")\n",
    "save_path += \"/PascalPartOntology_\"\n",
    "dataset = OntologyDataset(params,save_path)\n",
    "\n",
    "cEmb_init = torch.zeros(dataset.conceptSize-2, individualSize)\n",
    "rEmb_init = torch.zeros(1, individualSize, individualSize)\n",
    "# cEmb_init.fill_(0.5)\n",
    "# rEmb_init.fill_(0.5)\n",
    "\n",
    "true_rEmb = torch.zeros(1, individualSize, individualSize)\n",
    "for idx, (i,j) in enumerate(pairs_of_bb_idxs[partOf_of_pairs_of_data]):\n",
    "#     ci = dataset.concept2id['http://www.w3.org/2002/07/'+id2types[types_of_data[i]]]\n",
    "#     cj = dataset.concept2id['http://www.w3.org/2002/07/'+id2types[types_of_data[j]]]\n",
    "    true_rEmb[0,i,j] = 1 #\n",
    "    rEmb_init[0,i,j] = rEmb_candid[0,i,j]\n",
    "# rEmb_init = rEmb_candid.clone()\n",
    "\n",
    "\n",
    "\n",
    "def get_definers_initial_semantics(cid, use_partOf=False):\n",
    "    print(cid)\n",
    "    if use_partOf:\n",
    "        emb = torch.zeros(1,individualSize)\n",
    "        dataset.mode = 5\n",
    "        for left,right,neg in dataset:\n",
    "            print(left, right,neg)\n",
    "            if right.item() == cid:\n",
    "                emb = torch.max(torch.minimum(true_rEmb[0],cEmb_init[left[1]].unsqueeze(1).expand(true_rEmb[0].shape)),1).values + 0.1\n",
    "                break\n",
    "        dataset.mode = 0\n",
    "        \n",
    "        for left,right,neg in dataset:\n",
    "            print(left, right,neg)\n",
    "            if right.item() == cid:\n",
    "                emb = torch.maximum(cEmb_init[left.item()], emb) + 0.1\n",
    "        return emb\n",
    "    else:\n",
    "        dataset.mode = 2\n",
    "        for left,right,neg in dataset:\n",
    "            if left == cid:\n",
    "                if id2concept[right[0].item()][:7] == \"definer\":\n",
    "                    return torch.maximum(get_definers_initial_semantics(right[0],use_partOf=False),cEmb_init[right[1]]) - 0.1\n",
    "                return torch.maximum(cEmb_init[right[0]],cEmb_init[right[1]]) - 0.1\n",
    "                \n",
    "    \n",
    "    return torch.zeros(1,individualSize)\n",
    "\n",
    "cid2typeid = {} \n",
    "interest_cids = []\n",
    "cnt = 0\n",
    "id2concept = {c:idx for idx, c in dataset.concept2id.items()}\n",
    "\n",
    "                \n",
    "for c,idx in dataset.concept2id.items():\n",
    "    cname = c.replace(\"http://www.w3.org/2002/07/\",\"\")\n",
    "    if cname in selected_types_name:\n",
    "        cEmb_init[idx] = cEmb_candid[:,types[cname]]\n",
    "        cid2typeid[cnt] = types[cname]\n",
    "        interest_cids.append(True)\n",
    "        cnt += 1\n",
    "    else:\n",
    "        interest_cids.append(False)\n",
    "interest_cids = interest_cids[:-2]\n",
    "for c,idx in dataset.concept2id.items():\n",
    "    cname = c.replace(\"http://www.w3.org/2002/07/\",\"\")\n",
    "    if cname in selected_types_name: continue\n",
    "    if (idx == dataset.conceptSize -3) or (idx == dataset.conceptSize-4):continue\n",
    "    cEmb_init[idx] = get_definers_initial_semantics(idx,use_partOf=True)\n",
    "    print(torch.max(cEmb_init[idx]))\n",
    "        \n",
    "cEmb_init[-1] = torch.ones(1,individualSize)\n",
    "cEmb_init[-2] = torch.zeros(1,individualSize)\n",
    "\n",
    "id2types = {idx:name for name,idx in types.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "p_baseline = torch.argmax(cEmb_init[interest_cids],0).detach().numpy()\n",
    "h_baseline = np.array([cid2typeid[i] for i in p_baseline])\n",
    "\n",
    "y_true = []\n",
    "y_baseline = []\n",
    "for idx,t in enumerate(types_of_data):\n",
    "    if t in selected_types:\n",
    "        y_baseline.append(selected_types_name[np.where(selected_types==h_baseline[idx])[0][0]])\n",
    "        y_true.append(selected_types_name[np.where(selected_types==t)[0][0]])\n",
    "\n",
    "# confusion_matrix(y_true, y_pred, labels=selected_types_name)\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_baseline)\n",
    "print(precision_recall_fscore_support(y_true, y_baseline,average='macro'))\n",
    "print({selected_types_name[i]:s[i] for i in range(len(selected_types))})\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DF-ALC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\")\n",
    "import pickle\n",
    "params = {\n",
    "        \"conceptPath\": os.path.join(info_path,file_name+\"_concepts.txt\"),\n",
    "        \"rolePath\": os.path.join(info_path,file_name+\"_roles.txt\"),\n",
    "        \"individualPath\": os.path.join(info_path,file_name+\"_individuals.txt\"),\n",
    "        \"normalizationPath\": os.path.join(info_path,file_name+\"_normalization.txt\"),\n",
    "        \"batchSize\": 5,\n",
    "        \"epochSize\":10,\n",
    "        \"earlystopping\":10,\n",
    "        \"dist\": \"minkowski\",\n",
    "        \"norm\":1,\n",
    "        \"norm_rate\":0.3,\n",
    "        \"norm_rate2\":0.3,\n",
    "        \"alpha\": 0.5\n",
    "    }\n",
    "\n",
    "model = DFALC(params, conceptSize, roleSize, cEmb_init, rEmb_init, device).to(device)\n",
    "# model= nn.DataParallel(model,device_ids=[0, 1, 2,3])\n",
    "optimizer = optim.Adam(model.parameters(), 2e-4)\n",
    "\n",
    "\n",
    "nEpoch = 3000\n",
    "batchSz = 4\n",
    "best_loss = 100\n",
    "last_best_epoch = 0\n",
    "patience = 1\n",
    "best_f1 = 0\n",
    "best_cEmb = None\n",
    "for epoch in range(1, nEpoch+1):\n",
    "    loss_final, err_final = 0, 0\n",
    "    losses = torch.Tensor([0.0]).to(device)\n",
    "    for mode in range(7):\n",
    "        dataset.mode = mode\n",
    "        if len(dataset) == 0: continue\n",
    "        loader = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size=batchSz)\n",
    "        \n",
    "        for i, batch in enumerate(loader):\n",
    "            ptriplets = [b.to(device) for b in batch]\n",
    "            loss = model(ptriplets, mode, device)\n",
    "            losses += loss\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "    \n",
    "    p = torch.argmax(model.cEmb[torch.BoolTensor(interest_cids)],0).detach().cpu().numpy()\n",
    "    h = np.array([cid2typeid[i] for i in p])\n",
    "    y_pred = []\n",
    "    for idx,t in enumerate(types_of_data):\n",
    "        if t in selected_types:\n",
    "            y_pred.append(selected_types_name[np.where(selected_types==h[idx])[0][0]])\n",
    "    \n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(y_true, y_pred,average='macro')\n",
    "    print(\"Epoch {} loss {:.4f} precision {} recall {} f1 {}\".format(epoch,losses.item(),precision, recall, fbeta_score))\n",
    "    loss_final += losses.item()\n",
    "    if fbeta_score > best_f1:\n",
    "        best_f1 = fbeta_score\n",
    "        best_cEmb = model.cEmb.detach().cpu()\n",
    "        \n",
    "pickle.dump(best_cEmb,open(\"/data/data_wuxuan/SII/dfalc_data/testing/cEmb_\"+name+\".pkl\",\"wb\"))\n",
    "pickle.dump(model.rEmb,open(\"/data/data_wuxuan/SII/dfalc_data/testing/rEmb_\"+name+\".pkl\",\"wb\"))\n",
    "pickle.dump(cEmb_candid,open(\"/data/data_wuxuan/SII/dfalc_data/testing/true_cEmb_\"+name+\".pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cEmb = pickle.load(open(\"/data/data_wuxuan/SII/dfalc_data/testing/cEmb_vehicle.pkl\",\"rb\")).detach().cpu()\n",
    "rEmb = pickle.load(open(\"/data/data_wuxuan/SII/dfalc_data/testing/rEmb_vehicle.pkl\",\"rb\")).detach().cpu()\n",
    "cEmb_candid = pickle.load(open(\"/data/data_wuxuan/SII/dfalc_data/testing/true_cEmb_vehicle.pkl\",\"rb\")).detach().cpu()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "p = torch.argmax(cEmb[torch.BoolTensor(interest_cids)],0).detach().numpy()\n",
    "h = np.array([cid2typeid[i] for i in p])\n",
    "p_baseline = torch.argmax(cEmb_init[interest_cids],0).detach().numpy()\n",
    "h_baseline = np.array([cid2typeid[i] for i in p_baseline])\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_baseline = []\n",
    "for idx,t in enumerate(types_of_data):\n",
    "    if t in selected_types:\n",
    "        y_baseline.append(selected_types_name[np.where(selected_types==h_baseline[idx])[0][0]])\n",
    "        y_true.append(selected_types_name[np.where(selected_types==t)[0][0]])\n",
    "        y_pred.append(selected_types_name[np.where(selected_types==h[idx])[0][0]])\n",
    "print(len(y_true),len(y_pred))\n",
    "confusion_matrix(y_true, y_pred, labels=selected_types_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5d4ea6110d76bf407abdf3fc85b4f9a1bbb4f7f6454d667a509d28831b3322d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
